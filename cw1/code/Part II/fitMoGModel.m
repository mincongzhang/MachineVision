function MoGEst = fitMoGModel(data,nGaussEst,nIter)
%fitMoGModel
    %3 x N
    [nDim nData] = size(data);
    k = nGaussEst;
    
    %MAIN E-M ROUTINE 
    %there are nData data points, and there is a hidden variable associated
    %with each.  If the hidden variable is 0 this indicates that the data was
    %generated by the first Gaussian.  If the hidden variable is 1 then this
    %indicates that the hidden variable was generated by the second Gaussian
    %etc.
    
    postHidden = zeros(k, nData);%not sure
    
    %Initial data
    MoGEst.d = nDim; % d = 3
    MoGEst.k = k; % k = nDim = 3
    MoGEst.weight = (1/k)*ones(1,k);
    MoGEst.mean = 2*randn(nDim,k); %not sure
    for (cGauss =1:k)
        MoGEst.cov(:,:,cGauss) = (0.5+1.5*rand(1))*eye(nDim,nDim);
    end
    
    %calculate current likelihood
    logLike = getMixGaussLogLike(data,MoGEst);
    fprintf('Log Likelihood Iter 0 : %4.3f\n',logLike);
    
    %==========================================================================
    % E-Step & M-Step
    
    %nIter = 20;
    for (cIter = 1:nIter)
       %Expectation step
   
       for (cData = 1:nData)
            %calculate posterior probability that
            %this data point came from each of the Gaussians
            thisData = data(:,cData);
            for i =1:MoGEst.k
                %posterior (responsibilities)
                %postHidden(:,cData) = 1/k;
                postHidden(i,cData) = MoGEst.weight(i)*getGaussProb(thisData,MoGEst.mean(:,i),MoGEst.cov(:,:,i));
            end
            postHidden(:,cData) =  postHidden(:,cData)/sum(postHidden(:,cData),1);
       end
   
       %Maximization Step
   
       %for each constituent Gaussian
       for (cGauss = 1:k) 
            %Update weighting parameters mixGauss.weight based on the total
            %posterior probability associated with each Gaussian. Replace this:
            %mixGaussEst.weight(cGauss) = mixGaussEst.weight(cGauss); 
            MoGEst.weight(cGauss) = sum(postHidden(cGauss,:),2)/sum(sum(postHidden));
   
            %Update mean parameters mixGauss.mean by weighted average
            %where weights are given by posterior probability associated with
            %Gaussian.  Replace this:
            %mixGaussEst.mean(cGauss) = mixGaussEst.mean(cGauss);
            MoGEst.mean(:,cGauss) = postHidden(cGauss,:)*(data')./sum(postHidden(cGauss,:),2);
        
            %Update covarance parameter based on weighted average of
            %square distance from update mean, where weights are given by
            %posterior probability associated with Gaussian
            MoGEst.cov(:,:,cGauss) = zeros(size(data,1)); 
            for i =1:nData
                MoGEst.cov(:,:,cGauss) = MoGEst.cov(:,:,cGauss)+postHidden(cGauss,i)*(data(:,i)-MoGEst.mean(:,cGauss))*((data(:,i)-MoGEst.mean(:,cGauss))');
            end
            MoGEst.cov(:,:,cGauss) = MoGEst.cov(:,:,cGauss)./sum(postHidden(cGauss,:),2);
       end
   
       %draw the new solution
       %drawEMData2d(data,MoGEst);drawnow;

       %calculate the log likelihood
       logLike = getMixGaussLogLike(data,MoGEst);
       fprintf('Log Likelihood Iter %d : %4.3f\n',cIter,logLike);

    end
    
    % end of E-Step & M-Step
    %==========================================================================
    
end


%==========================================================================
%==========================================================================
function logLike = getMixGaussLogLike(data,MoGEst)
%the goal of this routine is to calculate the log likelihood for the whole
%data set under a mixture of Gaussians model. We calculate the log as the
%likelihood will probably be a very small number that Matlab may not be
%able to represent.


%find total number of data items
nData = size(data,2);

%initialize log likelihoods
logLike = 0;

%run through each data item
    for(cData = 1:nData)
        thisData = data(:,cData);    
        %calculate likelihood of this data point under mixture of Gaussians model
        like = 0;
        for i = 1:MoGEst.k
            normal = getGaussProb(thisData,MoGEst.mean(:,i),MoGEst.cov(:,:,i));
            like = like+(MoGEst.weight(i)).*normal;
        end
    
        %add to total log like
        logLike = logLike+log(like);        
    end
end


%==========================================================================
%==========================================================================
function prob = getGaussProb(x,mean,var)
    %return gaussian probabilities
    x_length = length(x);
    prob = 1./((2*pi)^x_length*det(var))^0.5*exp(-0.5*(x-mean)'*(var^(-1))*(x-mean));
end